# Minima

**Category:** AI Integration, MCP Servers

**Website:** [Minima on DEV.to](https://dev.to/dmayboroda/deployable-on-premises-rag)

---

## Description
Minima is an open-source, containerized Retrieval-Augmented Generation (RAG) solution designed for on-premises deployment or integration with external large language models (LLMs) such as ChatGPT or Anthropic Claude. It enables secure, flexible, and private AI workflows for handling local data using the Model Context Protocol (MCP).

---

## Features
- **Deployment Modes:**
  - **Isolated Installation:**
    - Fully on-premises operation with no external dependencies.
    - All neural networks (LLM, reranker, and embedding) run locally or in your own cloud.
    - Ensures data privacy and security.
  - **Custom GPT Integration:**
    - Query local documents via the ChatGPT app or web interface using custom GPTs.
    - Local or cloud-based indexer with ChatGPT as the LLM.
  - **Anthropic Claude Integration:**
    - Query local documents using the Claude app.
    - Local indexer with Anthropic Claude as the LLM.
- **Security:** Data remains local for on-premises mode, prioritizing privacy.
- **Flexibility:** Can be used fully locally or with popular external LLMs.
- **Containerized:** Easy deployment and management.
- **Open Source:** Source code available for customization and inspection.

---

## Pricing
No pricing information provided; Minima is open-source.

---

## Tags
mcp, rag, ai-integration, data-access
